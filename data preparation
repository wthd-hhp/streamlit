import rdkit
import pandas as pd
import numpy as np
from collections import Counter

from rdkit import Chem
from rdkit.Chem import Descriptors
from rdkit.ML.Descriptors import MoleculeDescriptors
from mordred import Calculator, descriptors
from warnings import simplefilter
simplefilter(action='ignore', category=FutureWarning)

experimental_data = pd.read_excel('298.15k下的气态热容.xlsx',index_col=0)
experimental_data

import os
folder_path = 'SDFdata/'
files = []
for filename in os.listdir(folder_path):
    if os.path.isfile(os.path.join(folder_path, filename)):
        files.append(filename)
print(files)

mols = []
fail = []
for i in files:
    suppl = Chem.SDMolSupplier(folder_path + str(i),strictParsing=False)
    if suppl[0] is not None:
        mols.append(suppl[0])
    else:
        fail.append(i)
mols
print("有%d个读取失败的,文件名称%s"%(len(fail),fail))

print("有%d个读取失败的,文件名称%s"%(len(fail),fail))
for i in fail:
    files.remove(i)
print("删除后有%d个分子"%(len(files)))

# 比较Rdkit与Mordred分子描述符 
calc = Calculator(descriptors, ignore_3D=True)
Mordred_description = []
Rdkit_description = [x[0] for x in Descriptors._descList]
for i in calc.descriptors:
    Mordred_description.append(i.__str__())
for i in Mordred_description:
    if i in Rdkit_description:
        Rdkit_description.remove(i)
        
Molecular_descriptor = []

descriptor_calculator = MoleculeDescriptors.MolecularDescriptorCalculator(Rdkit_description)
j =0
for i in mols:
    Calculator_descript = pd.DataFrame(calc.pandas([i]))
    rdkit_descriptors = pd.DataFrame([descriptor_calculator.CalcDescriptors(i)],columns=Rdkit_description)
    Calculator_descript = Calculator_descript.join(rdkit_descriptors)
    Molecular_descriptor.append(Calculator_descript)
    j+=1
    print(j)
    
a = Molecular_descriptor[0]
for i in Molecular_descriptor[1:]:
    a = a.append(i)
a = a.reset_index(drop=True)
# 删除计算失败的值
a = a.drop(labels=a.dtypes[a.dtypes == "object"].index,axis=1)
a
# 将分子描述符与预测值结合
NAME = [x.replace("-3d","").replace(".sdf","").replace("-2d", "").replace(".mol","") for x in files]
a.insert(0,"NAME",NAME)
a
import math

# lef_series_index = [x.replace("\xa0","") for x in experimental_data["3dSD"].values]
y_series_index = []
for x in experimental_data["CAS"].values:
    if type(x) == str:
        y_series_index.append(x.replace("\xa0",""))
    else:
        y_series_index.append(x)
        
for i in range(len(y_series_index)):
    if type(y_series_index[i])!=str:
        y_series_index[i] = y_series_index[i-1]
y_series_value = [float(x) for x in experimental_data["Cp (J/mol.K)"].values] 
y_series = pd.Series(y_series_value)
y_series.index = y_series_index
y_series = pd.DataFrame(y_series)
y_series
final_data = pd.DataFrame()
for i in a["NAME"]:
    temp_data = pd.DataFrame()
    for j in range(y_series[y_series.index == i].shape[0]):
        temp_data = temp_data.append(a[a["NAME"] ==i])
    temp_data.insert(1,"Cp",y_series[y_series.index ==i].values)
    final_data = final_data.append(temp_data)
        
final_data   
# 删除0值和空值
consolidated_data  = final_data.dropna(axis=1,how='any')
print(consolidated_data.shape)
data0=(consolidated_data==0).sum(axis = 0)
number0 = data0[data0>=final_data.shape[0]/2]
number0.index
consolidated_data = consolidated_data.drop(labels=number0.index,axis=1)
print(consolidated_data.shape)
consolidated_data.head()
# 删除低方差的值
var_data = consolidated_data.iloc[:,2:].var()
del_col = var_data[var_data<0.1].index
consolidated_data = consolidated_data.drop(labels=del_col,axis=1)
print(consolidated_data.shape)
consolidated_data.head()
# 删除重复值多的列
Duplicated_series=pd.Series(np.zeros(len(consolidated_data.columns)))
Duplicated_series.index = consolidated_data.columns.values
for i in consolidated_data.columns:
    Duplicated_series[i] = len(Counter(consolidated_data[i]))
    
Duplicated_series = Duplicated_series.sort_values(0)    
# Duplicated_series60 = Duplicated_series[Duplicated_series>60]    
Duplicated_series15 = Duplicated_series[Duplicated_series<=final_data.shape[0]/10]
consolidated_data = consolidated_data.drop(labels=Duplicated_series15.index,axis=1)
print(consolidated_data.shape)
consolidated_data.head()
correlation = consolidated_data.iloc[:,1:].corr('spearman')
correlation
df_bool = (abs(correlation) > 0.85)
correlation[df_bool]
DN_correlation = consolidated_data.iloc[:,1:].corr('spearman')["Cp"]
DN_correlation[DN_correlation>0.1]
bb = []
col_index = correlation.index
for i in range(0,len(col_index)):
    for j in range(i+1,len(col_index)):
        bb.append([col_index[i],col_index[j]])
k = 0
del_list = []
for i in bb:
    if not math.isnan(correlation[df_bool].loc[i[0],i[1]]) and ('Cp'not in i):
        k+=1
        if abs(DN_correlation[i[0]])>abs(DN_correlation[i[1]]):
            if i[1] not in del_list:
                del_list.append(i[1])
        else:
            if i[0] not in del_list:
                del_list.append(i[0])
            
print(del_list)
k 
Test_data = consolidated_data.drop(labels=del_list,axis=1)
Test_data
Test_data.to_excel("Cp-descriptor75.xlsx")
